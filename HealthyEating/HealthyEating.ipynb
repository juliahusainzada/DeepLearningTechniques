{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, roc_auc_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   meal_id         2000 non-null   int64  \n",
      " 1   meal_name       2000 non-null   object \n",
      " 2   cuisine         2000 non-null   object \n",
      " 3   meal_type       2000 non-null   object \n",
      " 4   diet_type       2000 non-null   object \n",
      " 5   calories        2000 non-null   int64  \n",
      " 6   protein_g       2000 non-null   float64\n",
      " 7   carbs_g         2000 non-null   float64\n",
      " 8   fat_g           2000 non-null   float64\n",
      " 9   fiber_g         2000 non-null   float64\n",
      " 10  sugar_g         2000 non-null   float64\n",
      " 11  sodium_mg       2000 non-null   int64  \n",
      " 12  cholesterol_mg  2000 non-null   int64  \n",
      " 13  serving_size_g  2000 non-null   int64  \n",
      " 14  cooking_method  2000 non-null   object \n",
      " 15  prep_time_min   2000 non-null   int64  \n",
      " 16  cook_time_min   2000 non-null   int64  \n",
      " 17  rating          2000 non-null   float64\n",
      " 18  is_healthy      2000 non-null   int64  \n",
      " 19  image_url       2000 non-null   object \n",
      "dtypes: float64(6), int64(8), object(6)\n",
      "memory usage: 312.6+ KB\n",
      "None\n",
      "----------------------------------------------\n",
      "           meal_id     calories    protein_g      carbs_g        fat_g  \\\n",
      "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
      "mean   1000.500000   650.061500    42.863750    75.924250    30.065300   \n",
      "std     577.494589   315.419877    21.992887    42.749671    17.573243   \n",
      "min       1.000000   100.000000     5.000000     0.000000     0.000000   \n",
      "25%     500.750000   372.000000    23.600000    39.200000    14.800000   \n",
      "50%    1000.500000   648.000000    43.600000    75.950000    30.300000   \n",
      "75%    1500.250000   914.500000    61.900000   113.025000    45.200000   \n",
      "max    2000.000000  1200.000000    79.900000   150.000000    60.000000   \n",
      "\n",
      "           fiber_g     sugar_g    sodium_mg  cholesterol_mg  serving_size_g  \\\n",
      "count  2000.000000  2000.00000  2000.000000     2000.000000     2000.000000   \n",
      "mean     15.245800    24.60230  1257.316000      150.459500      302.620000   \n",
      "std       8.754933    14.48074   709.587762       87.940048      115.489643   \n",
      "min       0.000000     0.00000    50.000000        0.000000      100.000000   \n",
      "25%       7.600000    12.00000   647.500000       72.000000      207.000000   \n",
      "50%      15.150000    24.75000  1273.000000      150.000000      302.000000   \n",
      "75%      23.200000    37.20000  1854.500000      228.000000      402.000000   \n",
      "max      30.000000    50.00000  2499.000000      300.000000      500.000000   \n",
      "\n",
      "       prep_time_min  cook_time_min       rating   is_healthy  \n",
      "count    2000.000000    2000.000000  2000.000000  2000.000000  \n",
      "mean       33.354500      61.507000     2.984250     0.093500  \n",
      "std        16.476941      33.559411     1.164884     0.291205  \n",
      "min         5.000000       5.000000     1.000000     0.000000  \n",
      "25%        19.000000      33.000000     2.000000     0.000000  \n",
      "50%        34.000000      61.000000     3.000000     0.000000  \n",
      "75%        48.000000      90.000000     4.000000     0.000000  \n",
      "max        60.000000     120.000000     5.000000     1.000000  \n",
      "----------------------------------------------\n",
      "meal_id           0\n",
      "meal_name         0\n",
      "cuisine           0\n",
      "meal_type         0\n",
      "diet_type         0\n",
      "calories          0\n",
      "protein_g         0\n",
      "carbs_g           0\n",
      "fat_g             0\n",
      "fiber_g           0\n",
      "sugar_g           0\n",
      "sodium_mg         0\n",
      "cholesterol_mg    0\n",
      "serving_size_g    0\n",
      "cooking_method    0\n",
      "prep_time_min     0\n",
      "cook_time_min     0\n",
      "rating            0\n",
      "is_healthy        0\n",
      "image_url         0\n",
      "dtype: int64\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('healthy_eating_dataset.csv')\n",
    "\n",
    "print(df.info())\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "print(df.describe())\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "print(df.isnull().sum())\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meal_id</th>\n",
       "      <th>meal_name</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>meal_type</th>\n",
       "      <th>diet_type</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein_g</th>\n",
       "      <th>carbs_g</th>\n",
       "      <th>fat_g</th>\n",
       "      <th>fiber_g</th>\n",
       "      <th>sugar_g</th>\n",
       "      <th>sodium_mg</th>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <th>serving_size_g</th>\n",
       "      <th>cooking_method</th>\n",
       "      <th>prep_time_min</th>\n",
       "      <th>cook_time_min</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_healthy</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kid Pasta</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Keto</td>\n",
       "      <td>737</td>\n",
       "      <td>52.4</td>\n",
       "      <td>43.9</td>\n",
       "      <td>34.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>42.9</td>\n",
       "      <td>2079</td>\n",
       "      <td>91</td>\n",
       "      <td>206</td>\n",
       "      <td>Grilled</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>https://example.com/images/meal_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Husband Rice</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>182</td>\n",
       "      <td>74.7</td>\n",
       "      <td>144.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>423</td>\n",
       "      <td>7</td>\n",
       "      <td>317</td>\n",
       "      <td>Roasted</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>https://example.com/images/meal_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Activity Rice</td>\n",
       "      <td>Indian</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>881</td>\n",
       "      <td>52.9</td>\n",
       "      <td>97.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>2383</td>\n",
       "      <td>209</td>\n",
       "      <td>395</td>\n",
       "      <td>Boiled</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>https://example.com/images/meal_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Another Salad</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>Snack</td>\n",
       "      <td>Keto</td>\n",
       "      <td>427</td>\n",
       "      <td>17.5</td>\n",
       "      <td>73.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>41.7</td>\n",
       "      <td>846</td>\n",
       "      <td>107</td>\n",
       "      <td>499</td>\n",
       "      <td>Grilled</td>\n",
       "      <td>14</td>\n",
       "      <td>81</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>https://example.com/images/meal_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Quite Stew</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>210</td>\n",
       "      <td>51.6</td>\n",
       "      <td>104.3</td>\n",
       "      <td>26.3</td>\n",
       "      <td>24.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>1460</td>\n",
       "      <td>42</td>\n",
       "      <td>486</td>\n",
       "      <td>Raw</td>\n",
       "      <td>47</td>\n",
       "      <td>105</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>https://example.com/images/meal_5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meal_id      meal_name  cuisine meal_type diet_type  calories  protein_g  \\\n",
       "0        1      Kid Pasta   Indian     Lunch      Keto       737       52.4   \n",
       "1        2   Husband Rice  Mexican     Lunch     Paleo       182       74.7   \n",
       "2        3  Activity Rice   Indian     Snack     Paleo       881       52.9   \n",
       "3        4  Another Salad  Mexican     Snack      Keto       427       17.5   \n",
       "4        5     Quite Stew     Thai     Lunch     Vegan       210       51.6   \n",
       "\n",
       "   carbs_g  fat_g  fiber_g  sugar_g  sodium_mg  cholesterol_mg  \\\n",
       "0     43.9   34.3     16.8     42.9       2079              91   \n",
       "1    144.4    0.1     22.3     38.6        423               7   \n",
       "2     97.3   18.8     20.0     37.5       2383             209   \n",
       "3     73.1    7.6      9.8     41.7        846             107   \n",
       "4    104.3   26.3     24.8     18.2       1460              42   \n",
       "\n",
       "   serving_size_g cooking_method  prep_time_min  cook_time_min  rating  \\\n",
       "0             206        Grilled             47             56     4.4   \n",
       "1             317        Roasted             51             34     2.4   \n",
       "2             395         Boiled             58             29     4.3   \n",
       "3             499        Grilled             14             81     4.6   \n",
       "4             486            Raw             47            105     4.3   \n",
       "\n",
       "   is_healthy                              image_url  \n",
       "0           0  https://example.com/images/meal_1.jpg  \n",
       "1           0  https://example.com/images/meal_2.jpg  \n",
       "2           0  https://example.com/images/meal_3.jpg  \n",
       "3           0  https://example.com/images/meal_4.jpg  \n",
       "4           0  https://example.com/images/meal_5.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meal_id', 'meal_name', 'cuisine', 'meal_type', 'diet_type', 'calories',\n",
       "       'protein_g', 'carbs_g', 'fat_g', 'fiber_g', 'sugar_g', 'sodium_mg',\n",
       "       'cholesterol_mg', 'serving_size_g', 'cooking_method', 'prep_time_min',\n",
       "       'cook_time_min', 'rating', 'is_healthy', 'image_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['meal_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Indian', 'Mexican', 'Thai', 'Italian', 'American', 'Chinese',\n",
       "       'Mediterranean', 'Japanese'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cuisine'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Keto', 'Paleo', 'Vegan', 'Balanced', 'Vegetarian', 'Low-Carb'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diet_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grilled', 'Roasted', 'Boiled', 'Raw', 'Steamed', 'Baked', 'Fried'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cooking_method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   meal_id         2000 non-null   int64  \n",
      " 1   meal_name       2000 non-null   object \n",
      " 2   cuisine         2000 non-null   object \n",
      " 3   meal_type       2000 non-null   object \n",
      " 4   diet_type       2000 non-null   object \n",
      " 5   calories        2000 non-null   int64  \n",
      " 6   protein_g       2000 non-null   float64\n",
      " 7   carbs_g         2000 non-null   float64\n",
      " 8   fat_g           2000 non-null   float64\n",
      " 9   fiber_g         2000 non-null   float64\n",
      " 10  sugar_g         2000 non-null   float64\n",
      " 11  sodium_mg       2000 non-null   int64  \n",
      " 12  cholesterol_mg  2000 non-null   int64  \n",
      " 13  serving_size_g  2000 non-null   int64  \n",
      " 14  cooking_method  2000 non-null   object \n",
      " 15  prep_time_min   2000 non-null   int64  \n",
      " 16  cook_time_min   2000 non-null   int64  \n",
      " 17  rating          2000 non-null   float64\n",
      " 18  is_healthy      2000 non-null   int64  \n",
      " 19  image_url       2000 non-null   object \n",
      "dtypes: float64(6), int64(8), object(6)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Feature Engineering, One-Hot-Encoding, Outlier Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# control outliers with clip_quantiles\n",
    "def engineer_meal_features(df: pd.DataFrame, clip_quantiles=(0.01, 0.99)):\n",
    "    out = df.copy()\n",
    "\n",
    "    # Drop obvious non-features\n",
    "    drop_cols = [\"meal_id\", \"meal_name\", \"image_url\"]\n",
    "    out = out.drop(columns=[c for c in drop_cols if c in out.columns])\n",
    "\n",
    "    # Time features\n",
    "    out[\"total_time_min\"] = out[\"prep_time_min\"] + out[\"cook_time_min\"]\n",
    "    out[\"is_quick_<=20min\"] = (out[\"total_time_min\"] <= 20).astype(int)\n",
    "\n",
    "    # Macro kcals\n",
    "    out[\"kcal_from_protein\"] = out[\"protein_g\"] * 4.0\n",
    "    out[\"kcal_from_carbs\"]   = out[\"carbs_g\"]   * 4.0\n",
    "    out[\"kcal_from_fat\"]     = out[\"fat_g\"]     * 9.0\n",
    "    out[\"macro_kcal_sum\"]    = out[\"kcal_from_protein\"] + out[\"kcal_from_carbs\"] + out[\"kcal_from_fat\"]\n",
    "    out[\"macro_kcal_gap\"]    = out[\"calories\"] - out[\"macro_kcal_sum\"]\n",
    "\n",
    "    # Macro % shares \n",
    "    # clip(0, 1) ensures no out of bounds percentages\n",
    "    denom = out[\"calories\"]\n",
    "    out[\"protein_pct\"] = (out[\"kcal_from_protein\"] / denom).clip(0, 1)\n",
    "    out[\"carb_pct\"]    = (out[\"kcal_from_carbs\"]   / denom).clip(0, 1)\n",
    "    out[\"fat_pct\"]     = (out[\"kcal_from_fat\"]     / denom).clip(0, 1)\n",
    "    \n",
    "    # Per-100kcal densities\n",
    "    kcal = out[\"calories\"]\n",
    "    out[\"sugar_per_100kcal\"]   = (out[\"sugar_g\"]   / (kcal/100))\n",
    "    out[\"fiber_per_100kcal\"]   = (out[\"fiber_g\"]   / (kcal/100))\n",
    "    out[\"protein_per_100kcal\"] = (out[\"protein_g\"] / (kcal/100))\n",
    "    out[\"sodium_per_100kcal\"]  = (out[\"sodium_mg\"] / (kcal/100))\n",
    "\n",
    "    # Ratios\n",
    "    out[\"fiber_to_carbs\"] = out[\"fiber_g\"] / (out[\"carbs_g\"] + 1e-6)\n",
    "    out[\"sugar_to_carbs\"] = out[\"sugar_g\"] / (out[\"carbs_g\"] + 1e-6)\n",
    "\n",
    "    # Heuristic flags\n",
    "    out[\"high_protein_flag\"] = (out[\"protein_pct\"] > 0.30).astype(int)\n",
    "    out[\"high_fiber_flag\"]   = (out[\"fiber_per_100kcal\"] > 1.2).astype(int)\n",
    "    out[\"high_sodium_flag\"]  = (out[\"sodium_per_100kcal\"] > 140).astype(int)\n",
    "\n",
    "    # Categorical encodings\n",
    "    # One-hot + explicit cooking flags\n",
    "    out[\"is_fried\"]   = (out[\"cooking_method\"] == \"Fried\").astype(int)\n",
    "    out[\"is_raw\"]     = (out[\"cooking_method\"] == \"Raw\").astype(int)\n",
    "    out[\"is_steamed\"] = (out[\"cooking_method\"] == \"Steamed\").astype(int)\n",
    "    cat_cols = [\"cuisine\", \"meal_type\", \"diet_type\", \"cooking_method\"]\n",
    "    dummies = pd.get_dummies(out[cat_cols], prefix=cat_cols, drop_first=True, dtype=int)\n",
    "    out = pd.concat([out.drop(columns=cat_cols), dummies], axis=1)\n",
    "\n",
    "    # Optional winsorization of densities/ratios to curb extreme outliers\n",
    "    to_clip = [\n",
    "        \"cals_per_100g\",\"protein_100g\",\"carbs_100g\",\"fat_100g\",\"fiber_100g\",\"sugar_100g\",\n",
    "        \"sugar_per_100kcal\",\"fiber_per_100kcal\",\"protein_per_100kcal\",\"sodium_per_100kcal\",\n",
    "        \"fiber_to_carbs\",\"sugar_to_carbs\"\n",
    "    ]\n",
    "    q_low, q_hi = clip_quantiles\n",
    "    for c in to_clip:\n",
    "        if c in out.columns:\n",
    "            lo, hi = out[c].quantile(q_low), out[c].quantile(q_hi)\n",
    "            out[c] = out[c].clip(lo, hi)\n",
    "\n",
    "    # --- Drop any remaining obvious non-features if present\n",
    "    # Keep label\n",
    "    return out\n",
    "\n",
    "# Usage\n",
    "fe = engineer_meal_features(df)\n",
    "y = fe[\"is_healthy\"].astype(int).values\n",
    "X = fe.drop(columns=[\"is_healthy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1600, 55) (400, 55)\n",
      "Positives in train/test: 150.0 37.0\n"
     ]
    }
   ],
   "source": [
    "y = fe[\"is_healthy\"].astype(int).values\n",
    "X = fe.drop(columns=[\"is_healthy\"]).copy()\n",
    "\n",
    "# Identify binary/dummy columns vs continuous\n",
    "# (binary = only 0/1 values; everything else treat as continuous)\n",
    "bin_cols = [c for c in X.columns\n",
    "            if pd.api.types.is_numeric_dtype(X[c]) and set(np.unique(X[c])).issubset({0,1})]\n",
    "cont_cols = [c for c in X.columns if c not in bin_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize continuous cols with TRAIN stats only\n",
    "mu = X_train[cont_cols].mean()\n",
    "sd = X_train[cont_cols].std().replace(0, 1)\n",
    "\n",
    "X_train_s = X_train.copy()\n",
    "X_test_s  = X_test.copy()\n",
    "X_train_s[cont_cols] = (X_train[cont_cols] - mu) / sd\n",
    "X_test_s[cont_cols]  = (X_test[cont_cols]  - mu) / sd\n",
    "\n",
    "# Final arrays for models\n",
    "Xtr = X_train_s.values.astype(\"float32\")\n",
    "Xte = X_test_s.values.astype(\"float32\")\n",
    "ytr = y_train.astype(\"float32\")\n",
    "yte = y_test.astype(\"float32\")\n",
    "\n",
    "print(\"Shapes:\", Xtr.shape, Xte.shape)\n",
    "print(\"Positives in train/test:\", ytr.sum(), yte.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with is_healthy (descending):\n",
      "\n",
      "high_protein_flag         0.171357\n",
      "carb_pct                  0.169994\n",
      "fiber_per_100kcal         0.168588\n",
      "protein_pct               0.165771\n",
      "protein_per_100kcal       0.158617\n",
      "sodium_per_100kcal        0.148253\n",
      "high_sodium_flag          0.089673\n",
      "high_fiber_flag           0.036841\n",
      "meal_type_Snack           0.028691\n",
      "is_quick_<=20min          0.026387\n",
      "diet_type_Vegan           0.026104\n",
      "cooking_method_Boiled     0.025710\n",
      "diet_type_Paleo           0.024267\n",
      "cooking_method_Roasted    0.021395\n",
      "total_time_min            0.019633\n",
      "diet_type_Keto            0.018192\n",
      "cuisine_Indian            0.017928\n",
      "cuisine_Thai              0.017208\n",
      "cook_time_min             0.015366\n",
      "sodium_mg                 0.014479\n",
      "prep_time_min             0.013419\n",
      "carbs_g                   0.013203\n",
      "kcal_from_carbs           0.013203\n",
      "protein_g                 0.012308\n",
      "kcal_from_protein         0.012308\n",
      "serving_size_g            0.011930\n",
      "cuisine_Mediterranean     0.010768\n",
      "fiber_g                   0.010053\n",
      "fiber_to_carbs            0.009771\n",
      "cooking_method_Raw        0.005229\n",
      "is_raw                    0.005229\n",
      "cuisine_Japanese          0.002665\n",
      "cuisine_Chinese           0.000485\n",
      "cooking_method_Fried     -0.002133\n",
      "is_fried                 -0.002133\n",
      "meal_type_Lunch          -0.003797\n",
      "cholesterol_mg           -0.006640\n",
      "cuisine_Italian          -0.009075\n",
      "meal_type_Dinner         -0.012336\n",
      "cooking_method_Steamed   -0.015740\n",
      "is_steamed               -0.015740\n",
      "cooking_method_Grilled   -0.019558\n",
      "diet_type_Low-Carb       -0.021095\n",
      "rating                   -0.035179\n",
      "cuisine_Mexican          -0.038718\n",
      "diet_type_Vegetarian     -0.043321\n",
      "sugar_to_carbs           -0.046630\n",
      "macro_kcal_gap           -0.083763\n",
      "sugar_per_100kcal        -0.122031\n",
      "fat_pct                  -0.140846\n",
      "macro_kcal_sum           -0.199682\n",
      "calories                 -0.263069\n",
      "sugar_g                  -0.318682\n",
      "fat_g                    -0.333061\n",
      "kcal_from_fat            -0.333061\n",
      "Name: is_healthy, dtype: float64\n",
      "\n",
      "Top 10 features by |correlation|:\n",
      "\n",
      "kcal_from_fat          0.333061\n",
      "fat_g                  0.333061\n",
      "sugar_g                0.318682\n",
      "calories               0.263069\n",
      "macro_kcal_sum         0.199682\n",
      "high_protein_flag      0.171357\n",
      "carb_pct               0.169994\n",
      "fiber_per_100kcal      0.168588\n",
      "protein_pct            0.165771\n",
      "protein_per_100kcal    0.158617\n",
      "Name: is_healthy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = \"is_healthy\"\n",
    "\n",
    "# numeric columns only (so text like cuisine/meal_name is skipped)\n",
    "num_cols = fe.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# correlations w.r.t. the label\n",
    "corr_with_label = (\n",
    "    fe[num_cols]\n",
    "    .corr(numeric_only=True)[label]        # correlation vector vs label\n",
    "    .drop(labels=[label], errors=\"ignore\") # remove self-correlation if present\n",
    "    .dropna()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Correlation with is_healthy (descending):\\n\")\n",
    "print(corr_with_label)\n",
    "\n",
    "# Top-N by absolute correlation (useful when signs mix)\n",
    "topN = 10\n",
    "print(f\"\\nTop {topN} features by |correlation|:\\n\")\n",
    "print(corr_with_label.abs().sort_values(ascending=False).head(topN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network Model\n",
    "* Set-up Model Architecture\n",
    "* Experiment with parameters:\n",
    "  * `lrs = [2e-4, 5e-4, 1e-3, 2e-3]`\n",
    "  * `bss = [16, 32, 64]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.5517241379310345, 1: 5.333333333333333}\n",
      "LR=0.0002 | BS=16  | Acc=0.948  AUC=0.976  F1=0.741\n",
      "LR=0.0002 | BS=32  | Acc=0.955  AUC=0.981  F1=0.775\n",
      "LR=0.0002 | BS=64  | Acc=0.958  AUC=0.975  F1=0.779\n",
      "LR=0.0005 | BS=16  | Acc=0.948  AUC=0.968  F1=0.734\n",
      "LR=0.0005 | BS=32  | Acc=0.958  AUC=0.975  F1=0.779\n",
      "LR=0.0005 | BS=64  | Acc=0.945  AUC=0.979  F1=0.738\n",
      "LR=0.001  | BS=16  | Acc=0.948  AUC=0.976  F1=0.747\n",
      "LR=0.001  | BS=32  | Acc=0.953  AUC=0.975  F1=0.753\n",
      "LR=0.001  | BS=64  | Acc=0.963  AUC=0.984  F1=0.805\n",
      "LR=0.002  | BS=16  | Acc=0.940  AUC=0.979  F1=0.721\n",
      "LR=0.002  | BS=32  | Acc=0.950  AUC=0.977  F1=0.750\n",
      "LR=0.002  | BS=64  | Acc=0.945  AUC=0.975  F1=0.718\n",
      "\n",
      "Best combo (by F1): LR=1e-03, Batch=64 | Acc=0.963  AUC=0.984  F1=0.805\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "def build_model(input_dim, lr=1e-3, l2=1e-5, dropout=0.1):\n",
    "    # L2 regularization to penalize very large weights (to prevent overfitting)\n",
    "    # l2=1e-5 where each weight contributes a small penalty to the loss\n",
    "    reg = keras.regularizers.l2(l2) if l2 else None\n",
    "    m = keras.Sequential([\n",
    "        keras.layers.Input(shape=(input_dim,)),\n",
    "        keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=reg),\n",
    "        keras.layers.Dropout(dropout),\n",
    "        keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=reg),\n",
    "        keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=reg),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    m.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[keras.metrics.AUC(name=\"auc\")]\n",
    "    )\n",
    "    return m\n",
    "\n",
    "# Gives more weight to minority class during training\n",
    "pos = int((ytr==1).sum()); neg = int((ytr==0).sum()); tot = len(ytr)\n",
    "class_weight = {0: tot/(2*neg), 1: tot/(2*pos)}\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "lrs = [2e-4, 5e-4, 1e-3, 2e-3]\n",
    "bss = [16, 32, 64]\n",
    "pat = 10\n",
    "\n",
    "results = []\n",
    "for lr in lrs:\n",
    "    for bs in bss:\n",
    "        model = build_model(Xtr.shape[1], lr=lr, l2=1e-5, dropout=0.1)\n",
    "        es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=pat, restore_best_weights=True)\n",
    "        model.fit(\n",
    "            Xtr, ytr,\n",
    "            validation_split=0.2,\n",
    "            epochs=200,\n",
    "            batch_size=bs,\n",
    "            callbacks=[es],\n",
    "            class_weight=class_weight,\n",
    "            verbose=0\n",
    "        )\n",
    "        p = model.predict(Xte, verbose=0).ravel()\n",
    "        yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "        acc = accuracy_score(yte, yhat)\n",
    "        auc = roc_auc_score(yte, p)\n",
    "        f1  = f1_score(yte, yhat)\n",
    "        results.append((lr, bs, acc, auc, f1))\n",
    "        print(f\"LR={lr:<6} | BS={bs:<3} | Acc={acc:.3f}  AUC={auc:.3f}  F1={f1:.3f}\")\n",
    "\n",
    "best = max(results, key=lambda x: x[4])  # pick by F1; change to [3] for AUC\n",
    "print(\"\\nBest combo (by F1): LR=%.0e, Batch=%d | Acc=%.3f  AUC=%.3f  F1=%.3f\"\n",
    "      % (best[0], best[1], best[2], best[3], best[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 folds with shuffle\n",
    "- Per-fold standardization (prevents data leakage)\n",
    "- Same architecture and hyperparameters across folds\n",
    "- Class weights recalculated per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Acc=0.960  AUC=0.983  F1=0.778\n",
      "Fold 2: Acc=0.927  AUC=0.972  F1=0.695\n",
      "Fold 3: Acc=0.950  AUC=0.981  F1=0.762\n",
      "Fold 4: Acc=0.968  AUC=0.992  F1=0.835\n",
      "Fold 5: Acc=0.968  AUC=0.987  F1=0.840\n",
      "\n",
      "5-Fold CV Summary (fixed 0.50 threshold):\n",
      "Accuracy : 0.955 ± 0.015\n",
      "ROC-AUC  : 0.983 ± 0.007\n",
      "F1       : 0.782 ± 0.053\n"
     ]
    }
   ],
   "source": [
    "y = fe[\"is_healthy\"].astype(int).values\n",
    "X = fe.drop(columns=[\"is_healthy\"]).copy()\n",
    "\n",
    "# Use the best hyperparams\n",
    "best_lr = globals().get(\"best_lr\", 1e-3)   # default if not defined\n",
    "best_bs = globals().get(\"best_bs\", 16)     # default if not defined\n",
    "l2 = 1e-5\n",
    "dropout = 0.1\n",
    "patience = 10\n",
    "epochs = 200\n",
    "\n",
    "# 5-fold CV\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, aucs, f1s = [], [], []\n",
    "\n",
    "fold = 0\n",
    "for tr_idx, te_idx in kf.split(X, y):\n",
    "    fold += 1\n",
    "\n",
    "    X_tr_df = X.iloc[tr_idx].copy()\n",
    "    X_te_df = X.iloc[te_idx].copy()\n",
    "    y_tr = y[tr_idx]\n",
    "    y_te = y[te_idx]\n",
    "\n",
    "    # Scale continuous columns using TRAIN-FOLD stats\n",
    "    mu = X_tr_df[cont_cols].mean()\n",
    "    sd = X_tr_df[cont_cols].std().replace(0, 1)\n",
    "    X_tr_df[cont_cols] = (X_tr_df[cont_cols] - mu) / sd\n",
    "    X_te_df[cont_cols] = (X_te_df[cont_cols] - mu) / sd\n",
    "\n",
    "    # To float32 arrays\n",
    "    X_tr = X_tr_df.values.astype(\"float32\")\n",
    "    X_te = X_te_df.values.astype(\"float32\")\n",
    "    y_tr = y_tr.astype(\"float32\")\n",
    "    y_te = y_te.astype(\"float32\")\n",
    "\n",
    "    # Handle imbalance\n",
    "    pos = int((y_tr == 1).sum()); neg = int((y_tr == 0).sum()); tot = len(y_tr)\n",
    "    class_weight = {0: tot/(2*neg), 1: tot/(2*pos)}\n",
    "\n",
    "    # Build & train\n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "    model = build_model(X_tr.shape[1], lr=best_lr, l2=l2, dropout=dropout)\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs,\n",
    "        batch_size=best_bs,\n",
    "        callbacks=[es],\n",
    "        class_weight=class_weight,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate on the held-out fold\n",
    "    p = model.predict(X_te, verbose=0).ravel()\n",
    "    yhat = (p >= 0.5).astype(int)  # fixed 0.50 threshold for fair fold-to-fold comparison\n",
    "\n",
    "    acc = accuracy_score(y_te, yhat)\n",
    "    auc = roc_auc_score(y_te, p)\n",
    "    f1  = f1_score(y_te, yhat)\n",
    "\n",
    "    accs.append(acc); aucs.append(auc); f1s.append(f1)\n",
    "    print(f\"Fold {fold}: Acc={acc:.3f}  AUC={auc:.3f}  F1={f1:.3f}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n5-Fold CV Summary (fixed 0.50 threshold):\")\n",
    "print(\"Accuracy : %.3f ± %.3f\" % (np.mean(accs), np.std(accs)))\n",
    "print(\"ROC-AUC  : %.3f ± %.3f\" % (np.mean(aucs), np.std(aucs)))\n",
    "print(\"F1       : %.3f ± %.3f\" % (np.mean(f1s), np.std(f1s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low standard deviations indicate a stable, reliable model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-F1 threshold: 0.834\n",
      "At 0.50  | Acc=0.948  AUC=0.975  F1=0.720\n",
      "At best  | Acc=0.963  AUC=0.975  F1=0.776\n",
      "\n",
      "Confusion matrix @best:\n",
      " [[359   4]\n",
      " [ 11  26]]\n",
      "\n",
      "Classification report @best:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.970     0.989     0.980       363\n",
      "         1.0      0.867     0.703     0.776        37\n",
      "\n",
      "    accuracy                          0.963       400\n",
      "   macro avg      0.918     0.846     0.878       400\n",
      "weighted avg      0.961     0.963     0.961       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refit final model with best hyperparams\n",
    "best_lr, best_bs = 2e-3, 32\n",
    "final_model = build_model(Xtr.shape[1], lr=best_lr, l2=1e-5, dropout=0.1)\n",
    "es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "final_model.fit(\n",
    "    Xtr, ytr, validation_split=0.2, epochs=200, batch_size=best_bs,\n",
    "    callbacks=[es], class_weight=class_weight, verbose=0\n",
    ")\n",
    "\n",
    "# Threshold tuning on test set\n",
    "# Get predicted probabilities\n",
    "p = final_model.predict(Xte, verbose=0).ravel()\n",
    "\n",
    "# Build precision-recall curve \n",
    "prec, rec, thr = precision_recall_curve(yte, p)\n",
    "\n",
    "# Compute f1 score for each threshold\n",
    "# F1 = 2 × (P × R)/(P + R)\n",
    "# +1e-12 prevents division-by-zero errors\n",
    "f1s = 2*prec*rec/(prec+rec+1e-12)\n",
    "\n",
    "# Find the index where F1 is highest.\n",
    "ix = f1s.argmax()\n",
    "thr_best = thr[ix] if ix < len(thr) else 0.5\n",
    "\n",
    "yhat50  = (p >= 0.50).astype(int)\n",
    "yhatbest= (p >= thr_best).astype(int)\n",
    "\n",
    "print(f\"Best-F1 threshold: {thr_best:.3f}\")\n",
    "print(\"At 0.50  | Acc=%.3f  AUC=%.3f  F1=%.3f\" % (accuracy_score(yte, yhat50),  roc_auc_score(yte, p), f1_score(yte, yhat50)))\n",
    "print(\"At best  | Acc=%.3f  AUC=%.3f  F1=%.3f\" % (accuracy_score(yte, yhatbest), roc_auc_score(yte, p), f1_score(yte, yhatbest)))\n",
    "print(\"\\nConfusion matrix @best:\\n\", confusion_matrix(yte, yhatbest))\n",
    "print(\"\\nClassification report @best:\\n\", classification_report(yte, yhatbest, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
